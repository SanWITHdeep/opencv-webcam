<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Emotion Mirror</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700&display=swap');
        body {
            font-family: 'Poppins', sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            background-color: #1a202c;
            color: #e2e8f0;
            overflow: hidden;
        }
        #video {
            position: fixed;
            bottom: 20px;
            right: 20px;
            width: 160px;
            height: 120px;
            border-radius: 12px;
            box-shadow: 0 10px 20px rgba(0,0,0,0.2);
            transform: scaleX(-1); /* Mirror the video feed */
            border: 2px solid #4a5568;
        }
        #status-container {
            position: fixed;
            top: 20px;
            left: 50%;
            transform: translateX(-50%);
            padding: 12px 24px;
            background-color: rgba(45, 55, 72, 0.8);
            border-radius: 9999px;
            backdrop-filter: blur(10px);
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            z-index: 100;
            display: flex;
            align-items: center;
            gap: 12px;
        }
        .loader {
            border: 4px solid #4a5568;
            border-top: 4px solid #6366f1;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .face-container {
            width: 350px;
            height: 350px;
            position: relative;
            display: flex;
            justify-content: center;
            align-items: center;
            transition: transform 0.3s ease-out;
        }
        #emotion-image {
            width: 100%;
            height: 100%;
            object-fit: contain;
            transition: opacity 0.2s ease-in-out;
        }
    </style>
</head>
<body>

    <div id="status-container">
        <div id="loader" class="loader"></div>
        <p id="status" class="text-lg font-semibold">Loading Models...</p>
    </div>

    <div class="face-container" id="face-container">
        <img id="emotion-image" src="neutral.png" alt="Facial Expression">
    </div>

    <video id="video" autoplay muted playsinline></video>

    <script>
        const video = document.getElementById('video');
        const statusText = document.getElementById('status');
        const loader = document.getElementById('loader');

        // Image and container elements
        const faceContainer = document.getElementById('face-container');
        const emotionImage = document.getElementById('emotion-image');

        // Function to start the webcam
        async function startVideo() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
                video.srcObject = stream;
            } catch (err) {
                console.error("Webcam Error:", err);
                statusText.textContent = "Error: Webcam access denied.";
                loader.style.display = 'none';
            }
        }

        // Load all the models from face-api.js
        async function loadModels() {
            const MODEL_URL = 'https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights';
            statusText.textContent = 'Loading AI Models...';
            await Promise.all([
                faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
                faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
                faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)
            ]);
            statusText.textContent = "Ready! Look at the camera.";
            loader.style.display = 'none';
        }

        // Main function to initialize everything
        async function main() {
            await loadModels();
            await startVideo();
        }

        main();

        video.addEventListener('play', () => {
            setInterval(async () => {
                const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceExpressions();

                if (detections) {
                    updateFace(detections);
                }
            }, 150); // Interval increased slightly for smoother image switching
        });

        function updateFace(detections) {
            // Determine the primary emotion
            const expressions = detections.expressions;
            const primaryEmotion = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
            statusText.textContent = `Emotion: ${primaryEmotion.charAt(0).toUpperCase() + primaryEmotion.slice(1)}`;
            
            // --- Switch Image based on Emotion ---
            let newImageSrc = 'neutral.png'; // Default image

            switch (primaryEmotion) {
                case 'happy':
                    newImageSrc = 'happy.png';
                    break;
                case 'sad':
                case 'angry': // Grouping angry with sad
                case 'fearful': // Grouping fearful with sad
                    newImageSrc = 'sad.png';
                    break;
                case 'surprised':
                    newImageSrc = 'surprised.png';
                    break;
                case 'neutral':
                default:
                    newImageSrc = 'neutral.png';
                    break;
            }

            // Only update the image source if it has changed to prevent flickering
            if (!emotionImage.src.endsWith(newImageSrc)) {
                emotionImage.src = newImageSrc;
            }

            // --- Head Tilt ---
            const landmarks = detections.landmarks;
            const jaw = landmarks.getJawOutline();
            // Calculate angle between the ends of the jawline
            const tiltAngle = Math.atan2(jaw[16].y - jaw[0].y, jaw[16].x - jaw[0].x) * (180 / Math.PI);
            faceContainer.style.transform = `rotate(${tiltAngle}deg)`;
        }
    </script>
</body>
</html>
